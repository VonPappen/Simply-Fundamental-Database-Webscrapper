{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "\n",
    "sys.path.append(\n",
    "        os.path.dirname(\n",
    "            os.path.realpath(\n",
    "                ''\n",
    "            )\n",
    "        )\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import requests, json, re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from itertools import repeat\n",
    "from database.database import Database\n",
    "\n",
    "class Macrotrend():\n",
    "        \n",
    "    def get_statement(self, ticker, statement, time_format):\n",
    "\n",
    "        statement_data = None #default load\n",
    "\n",
    "        if time_format == 'annual':\n",
    "\n",
    "            try:\n",
    "                r = requests.get('https://www.macrotrends.net/stocks/charts/' + ticker + '/' + ticker + '/' + statement)\n",
    "                print(ticker, r)\n",
    "                p = re.compile(r'var originalData = (.*);')\n",
    "                p2 = re.compile(r'datafields:[\\s\\S]+(\\[[\\s\\S]+?\\]),')\n",
    "                p3 = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "                data = json.loads(p.findall(r.text)[0])\n",
    "                s = re.sub('\\r|\\n|\\t|\\s','',p2.findall(r.text)[0])\n",
    "                fields = p3.findall(s)\n",
    "                fields.insert(0, 'field_name') # only headers of interest.\n",
    "                results = []\n",
    "\n",
    "                for item in data: #loop initial list of dictionaries\n",
    "                    row = {}\n",
    "                    for f in fields: #loop keys of interest to extract from current dictionary\n",
    "                        if f == 'field_name':  #this is an html value field so needs re-parsing\n",
    "                            soup2 = bs(item[f],'lxml')\n",
    "                            row[f] = soup2.select_one('a,span').text\n",
    "                        else:\n",
    "                            row[f] = item[f]\n",
    "                    results.append(row)\n",
    "\n",
    "                # return pd.DataFrame(results, columns = fields)\n",
    "                statement_data = pd.DataFrame(results, columns = fields)\n",
    "\n",
    "                return statement_data\n",
    "        \n",
    "            except:\n",
    "                print(f\"No data available for {ticker}, {statement}, annual\")\n",
    "                pass\n",
    "            # pass\n",
    "        else:\n",
    "\n",
    "            try:\n",
    "\n",
    "                r = requests.get(f'https://www.macrotrends.net/stocks/charts/' + ticker + '/' + ticker + '/' + statement)\n",
    "                company_name = r.url.split('/')[6]\n",
    "                r = requests.get(f'https://www.macrotrends.net/stocks/charts/'+ ticker + '/' + company_name + '/' + statement + '?freq=Q')\n",
    "                print(ticker, r)\n",
    "                p = re.compile(r'var originalData = (.*);')\n",
    "                p2 = re.compile(r'datafields:[\\s\\S]+(\\[[\\s\\S]+?\\]),')\n",
    "                p3 = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "                data = json.loads(p.findall(r.text)[0])\n",
    "                s = re.sub('\\r|\\n|\\t|\\s','',p2.findall(r.text)[0])\n",
    "                fields = p3.findall(s)\n",
    "                fields.insert(0, 'field_name') # only headers of interest.\n",
    "                results = []\n",
    "\n",
    "                for item in data: #loop initial list of dictionaries\n",
    "                    row = {}\n",
    "                    for f in fields: #loop keys of interest to extract from current dictionary\n",
    "                        if f == 'field_name':  #this is an html value field so needs re-parsing\n",
    "                            soup2 = bs(item[f],'lxml')\n",
    "                            row[f] = soup2.select_one('a,span').text\n",
    "                        else:\n",
    "                            row[f] = item[f]\n",
    "                    results.append(row)\n",
    "                statement_data = pd.DataFrame(results, columns = fields)\n",
    "\n",
    "                return statement_data\n",
    "\n",
    "            except:\n",
    "\n",
    "                print(f\"No data available for {ticker}, {statement}, quarterly\")\n",
    "\n",
    "                pass\n",
    "\n",
    "    def item_amount_unit(ticker, statement, time_format):\n",
    "\n",
    "        if time_format == \"annual\":\n",
    "\n",
    "            r = requests.get('https://www.macrotrends.net/stocks/charts/' + ticker + '/' + ticker + '/' + statement)\n",
    "            text = r.text\n",
    "            pattern = re.compile(r\"var columnList = (.*);\", re.DOTALL)\n",
    "            matches = pattern.findall(text)\n",
    "            matches = re.sub(\"\\r|\\n|\\t\",'',  matches[0])\n",
    "            pattern2 = re.compile(r\"'(.*?)'\")\n",
    "            match = pattern2.findall(str(matches))[0]\n",
    "\n",
    "            return str(match).split(\" | \")[1]\n",
    "\n",
    "        elif time_format == \"quarterly\":\n",
    "\n",
    "            r = requests.get(f'https://www.macrotrends.net/stocks/charts/' + ticker + '/' + ticker + '/' + statement)\n",
    "            company_name = r.url.split('/')[6]\n",
    "            r = requests.get(f'https://www.macrotrends.net/stocks/charts/'+ ticker + '/' + company_name + '/' + statement + '?freq=Q')\n",
    "            text = r.text\n",
    "            pattern = re.compile(r\"var columnList = (.*);\", re.DOTALL)\n",
    "            matches = pattern.findall(text)\n",
    "            matches = re.sub(\"\\r|\\n|\\t\",'',  matches[0])\n",
    "            pattern2 = re.compile(r\"'(.*?)'\")\n",
    "            match = pattern2.findall(str(matches))[0]\n",
    "\n",
    "            return str(match).split(\" | \")[1]\n",
    "\n",
    "    def move_column(self, df, column, pos):\n",
    "\n",
    "        col = df[column]\n",
    "        df.drop(columns=[column],inplace = True)\n",
    "        df.insert(pos, column, col)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def generate_statement_key(self, statement, time_format):\n",
    "\n",
    "        report_formats  = {'quarterly'  : 'Q',\n",
    "                            'annual'    : 'A'}\n",
    "        statements      = {'income-statement'       :'IS',\n",
    "                            'balance-sheet'         :'BS',\n",
    "                            'cash-flow-statement'   :'CF',\n",
    "                            'financial-ratios'      :'R'}\n",
    "\n",
    "        statement_key = statements[statement] + '-' + report_formats[time_format]\n",
    "\n",
    "        return statement_key\n",
    "\n",
    "    def arrange_data(self, ticker, statement, time_format):\n",
    "\n",
    "        data_dict = []\n",
    "        report_formats = {'quarterly' : 'Q',\n",
    "                        'annual': 'A'}\n",
    "        statements = {'income-statement':'IS',\n",
    "                    'balance-sheet':'BS',\n",
    "                    'cash-flow-statement':'CF',\n",
    "                    'financial-ratios':'R'}\n",
    "\n",
    "        # convert_dict = {\n",
    "        #     'date': str,\n",
    "        #     'statement': str,\n",
    "        #     'ticker': str,\n",
    "        #     'security_id': int,\n",
    "        #     'line_item': str,\n",
    "        #     # 'amount': float\n",
    "        # }\n",
    "\n",
    "        df = self.get_statement(ticker, statement, time_format)\n",
    "\n",
    "        if isinstance(df, pd.DataFrame):\n",
    "\n",
    "            for i in df.columns[1:]:\n",
    "                keys = df[df.columns[0]]\n",
    "                data = df[i].values\n",
    "                data = {k:v for k,v in zip(keys, data)}\n",
    "                date = i\n",
    "                data['date'] = date\n",
    "                data['ticker'] = ticker\n",
    "                data['statement_format'] = statements[statement] + '-' + report_formats[time_format]\n",
    "                data_dict.append(data)\n",
    "\n",
    "            df = pd.DataFrame(data_dict)\n",
    "            df = self.move_column(df, 'date', 0)\n",
    "            df = self.move_column(df, 'ticker', 1)\n",
    "            df = self.move_column(df, 'statement_format', 2)\n",
    "\n",
    "            my_series = []\n",
    "            line_item = []\n",
    "            amount = []\n",
    "            date = []\n",
    "            ticker = []\n",
    "            security_id = []\n",
    "            statement_format = []\n",
    "\n",
    "            for i in df.iterrows():\n",
    "\n",
    "                serie = pd.Series(i)[1]\n",
    "                # print(serie)\n",
    "                my_series.append(serie)\n",
    "                [statement_format.append(serie[2]) for i in range(len(serie.index.values[4:]))]\n",
    "                # [security_id.append(serie[3]) for i in range(len(serie.index.values[4:]))]\n",
    "                [line_item.append(i) for i in  serie.index.values[4:]]\n",
    "                [amount.append(i) for i in serie.values[4:]]\n",
    "                [date.append(serie[0]) for i in  range(len(serie.index.values[4:]))]\n",
    "                [ticker.append(serie[1]) for i in range(len(serie.index.values[4:]))]\n",
    "\n",
    "                print(serie.index.values[3])\n",
    "\n",
    "            data = pd.DataFrame([date, statement_format, ticker, security_id,line_item, amount]).T\n",
    "            data.columns = ['date','statement','ticker','security_id','line_item','amount']\n",
    "            data['statement_id'] = data['statement'] + \"_\" + data['date'].apply(lambda x: x.replace('-', '')) + \"_\" + data['ticker']\n",
    "            data['security_id'] = data['ticker'].map(Database().security_id_map())\n",
    "            # data = data.astype(convert_dict)\n",
    "            data['amount'] = pd.to_numeric(data['amount'])\n",
    "\n",
    "\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL <Response [200]>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1171905/2884066944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMacrotrend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrange_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AAPL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income-statement'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quarterly'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1171905/1926064047.py\u001b[0m in \u001b[0;36marrange_data\u001b[0;34m(self, ticker, statement, time_format)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'line_item'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecurity_id_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# data = data.astype(convert_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/DATABASE/PSQL_DATABASE/alc_env/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m~/Documents/projects/DATABASE/PSQL_DATABASE/alc_env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/DATABASE/PSQL_DATABASE/alc_env/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1100\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/projects/DATABASE/PSQL_DATABASE/alc_env/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1171905/1926064047.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecurity_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mline_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'line_item'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statement'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'security_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDatabase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecurity_id_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# data = data.astype(convert_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "M = Macrotrend()\n",
    "\n",
    "M.arrange_data('AAPL', 'income-statement', 'quarterly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7a4e82c337e93606b561376fb09413a18725649db2d1612488b8ebec5a3bdf5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('alc_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
